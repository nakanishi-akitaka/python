{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単純ベイズ分類器 (ナイーブベイズ, Naive Bayes Classifier)\n",
    "\n",
    "# 概要\n",
    "* クラス分類手法の一つであり、多クラス分類も可能  \n",
    "* ベイズの定理を利用  \n",
    "* 生成モデルの一つであり、クラス分類の結果が確率として得られる\n",
    "* それぞれの説明変数 (入力変数・記述子・特徴量) は独立していること (正確にいうと条件付き独立性) を仮定\n",
    "* 説明変数の分布 (正確には、クラスが与えられたときの説明変数の分布)を仮定する必要がある\n",
    "* 一般的には、正規分布かベルヌーイ分布\n",
    "\n",
    "# 分かりやすいと思った説明\n",
    "病気の検査で、陽性と出て、かつ病気の確率  \n",
    "（ベイズの定理より計算）  \n",
    "1回目の検査　数%でも、  \n",
    "2回目の検査　数十％になる  \n",
    "！精度が悪い検査でも繰り返すと精度を向上できる  \n",
    "→特徴量(独立！)の数だけ検査するようなもの  \n",
    "\n",
    "\n",
    "# 議論　なぜうまくいく？\n",
    "> 独立性の仮定を広範囲に適用することが正確性に欠けるという事実があるにもかかわらず、\n",
    "> 単純ベイズ分類器は実際には驚くほど有効である。特に、クラスの条件付き特徴分布を分離することは、\n",
    "> 各分布を1次元の分布として見積もることができることを意味している。\n",
    "> そのため、特徴数が増えることで指数関数的に必要なデータ集合が大きくなるという\n",
    "> 「次元の呪い」から生じる問題を緩和できる。MAP 規則を使った確率的分類器の常として、\n",
    "> 正しいクラスが他のクラスより尤もらしい場合に限り、正しいクラスに到達する。\n",
    "> それゆえ、クラス確率はうまく見積もられていなくてもよい。\n",
    "> 言い換えれば、根底にある単純な確率モデルの重大な欠陥を無効にするほど、\n",
    "> 分類器は全体として十分に頑健である。\n",
    "> 単純ベイズ分類器がうまく機能する理由についての議論は、後述の参考文献にもある。\n",
    "\n",
    "つまり、確率の「数値」はいい加減であっても、「大小関係」さえ合っていれば、分類は正しく行える、\n",
    "のがうまくいく原因であるらしい。\n",
    "\n",
    "# その他、引用\n",
    "## その１\n",
    "> ただ、文書中の「単語間の関係」についての仮定があまりにもシンプルすぎるが故に、「精度が低い」と指摘されているのも事実です。\n",
    "> いざ、文書分類をするためのアルゴリズムは多々あるので、\n",
    "> いざ実務で使う際は色々なアルゴリズムの特徴を把握する必要がありますが、\n",
    "> 「とりあえず文書分類をしてみて雰囲気を感じ取りたい」、\n",
    "> という場合はナイーブベイズを試してみるのも有効だと思います。\n",
    "\n",
    "## その２\n",
    "> 単純ベイズ分類器は英語ではNaive Bayes classifierと呼ばれます。\n",
    "> Naive Bayes classifierを訳すると「単純」と付けられていますが、\n",
    "> アルゴリズムが単純でわかりやすいという意味ではなく、\n",
    "> 「Naive=うぶな、ばか正直な、考えが甘い」という「データについてNaiveな想定」を置いているために、\n",
    "> 単純という言葉につながっているようです。\n",
    "> 決して、アルゴリズムの精度が悪いという意味でもなければ、\n",
    "> テキスト分類では、標準的なアルゴリズムとして広く利用されています。\n",
    ">\n",
    "> 「データについてNaiveな想定」とは、どういった意味なのかと言いますと、\n",
    "> 各特徴が独立という仮定を置いているためです。\n",
    "> 基本的に各言葉は独立ではない場合が多くあります。\n",
    "> 例えば、スパムメールには、「あの言葉が入っていれば、この言葉も入っている」ということが多いので、\n",
    "> 言葉は独立な関係ではありません。\n",
    "> にも関わらず、単純ベイズ分類器は非常に正しく分類が実行できてしまうようです。\n",
    "\n",
    "## その３\n",
    "> 今回取り上げるのは、よく使われていて実装も簡単、しかも高速というナイーブベイズです。\n",
    "> 精度評価のベースラインとしてよく使われてます。\n",
    "\n",
    "ゼロ頻度問題\n",
    "未知の文書のカテゴリを予測する際、訓練データのボキャブラリに含まれない単語を1つでも含んでいると\n",
    "単語の条件付き確率は0となり、単語の条件付き確率の積で表される確率も0となる\n",
    "\n",
    "# その４\n",
    "* 長所\n",
    "    * 単純(実装も簡単)かつ強力\n",
    "    * とても大きなデータセットに対しても有効\n",
    "    * 高速で計算資源も少なくてよい\n",
    "    * 少ないトレーニングデータでも性能が出る\n",
    "    * 重要でない特徴量の影響を受けにくい\n",
    "* 短所\n",
    "    * 各特徴量が独立であると仮定しなければならない(実データでは成り立たないことも多い)\n",
    "* 応用先\n",
    "    * リアルタイムでの処理、テキスト分類\n",
    "\n",
    "## その５　短所について\n",
    "> つまり各特徴量が独立に推定結果に影響します。\n",
    "> これはとても強い仮定で、実データでは成り立たないことも多いです。\n",
    "> 実はこれがNaiveと名前につく所以でもあるのですが、\n",
    "> その強い仮定(制約)にもかかわらず、この仮定が成り立たないであろう実データでも、\n",
    "> 驚くほどよい結果を出すというのがこのアルゴリズムの優秀な点です。\n",
    "「とりあえずナイーブベイズでテストしてみよう」と考えたくなる\n",
    "\n",
    "テキスト分類の場合、特徴量は単語の頻度になるので、確率は多項分布やベルヌーイ分布\n",
    "正規分布ではない\n",
    "\n",
    "## その６\n",
    "分類/回帰の基本がそれぞれ、ナイーブベイズと線形回帰らしい  \n",
    "どちらも、最適化するべきハイパーパラメータが存在しない  \n",
    "\n",
    "Q.ナイーブベイズはガウス関数使うなら、パラメータはあるのでは？  \n",
    "A.自動的に決まるらしい  \n",
    "https://datachemeng.com/naivebayesclassifier/\n",
    "> yのクラスごとに、説明変数Xごとに、データセットから平均μ(xi,y)標準偏差σ(xi,y)を計算\n",
    "\n",
    "\n",
    "# 参考文献\n",
    "* 単純ベイズ分類器 (ナイーブベイズ, Naive Bayes Classifier) でクラス分類  \n",
    "    https://datachemeng.com/naivebayesclassifier/\n",
    "* ベイズの定理とは？ナイーブベイズを利用した自動FAQシステムの構築  \n",
    "    https://ai-kenkyujo.com/2018/03/23/faq/\n",
    "* https://ja.wikipedia.org/wiki/%E5%8D%98%E7%B4%94%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E%E5%99%A8\n",
    "* https://dev.classmethod.jp/machine-learning/naivebaise_zakkurimatome_/\n",
    "* https://avinton.com/academy/naive-bayes/\n",
    "* ナイーブベイズ分類器を頑張って丁寧に解説してみる  \n",
    "    https://qiita.com/aflc/items/13fe52243c35d3b678b0\n",
    "* ナイーブベイズについて勉強したのでざっくりまとめ  \n",
    "    https://dev.classmethod.jp/machine-learning/naivebaise_zakkurimatome_/\n",
    "* 機械学習アルゴリズム〜単純ベイズ法〜   \n",
    "    http://rtokei.tech/machine-learning/機械学習アルゴリズム〜単純ベイズ法〜/\n",
    "* ナイーブベイズを用いたテキスト分類  \n",
    "    http://aidiary.hatenablog.com/entry/20100613/1276389337\n",
    "* 機械学習入門者向け Naive Bayes(単純ベイズ)アルゴリズムに触れてみる  \n",
    "    https://avinton.com/academy/naive-bayes/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
