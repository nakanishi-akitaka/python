# -*- coding: utf-8 -*-
"""
Created on Sat Jan 19 17:41:07 2019

@author: Akitaka
"""

[1] 機械学習
[1a] サイトで勉強　金子研究室
データ解析に関するいろいろな手法・考え方のまとめ
https://datachemeng.com/summarydataanalysis/

[1a2] 復習
バリデーション結果は、少数の比較には使ってよいが最適化に使ってはいけない！～外部バリデーションや
(ダブル)クロスバリデーションでは何を評価しているのか？評価するときのジレンマとは？～
https://datachemeng.com/validation_comparison_optimization/
ref
20181217
20181218

推定性能を評価する際の問題
NG手順
    1000サンプルで学習して、同じ1000 サンプルで推定性能を評価
        →新しいサンプルに対する推定性能を評価できない
OK手順
    700サンプルで学習して、300サンプルの推定結果を評価
    最終的に用いるモデルは、1000サンプルで再学習したモデル
仮定
    1000 サンプルで学習したモデルの、新しいサンプルに対する推定性能
    =700 サンプルで学習したモデルの、(以下同)
仮定からの要請
    1000サンプルで学習したモデル　～　700サンプルで学習したモデル
    1000サンプル　～　700サンプル
ジレンマ
    学習サンプル数を多くすると要請は満たされる
    一方で、検証サンプル数が減るので、推定性能評価の信頼性が落ちる

問題点
    以上の議論は、ハイパーパラメータが決まったモデルを比較する場合の話
    ハイパーパラメータの値の異なる、複数の PLS モデル + 複数の SVR モデル + ...
    を比較する場合には当てはまらない
        多数のモデルから選ぶと、300サンプルに過学習したものになるから
        少数のモデルから選ぶなら良し
    """
    ここがなぜなのかイマイチ分からなかった(20181217)
    今は何となく理解できる
    ハイパーパラメータが異なる、多数のモデルから選ぶとなると、
    どうとでもサンプルに合わせられる、あるいはそこまではいかずとも、
    特定の300サンプルに「たまたま合う」ようなもの(過学習したもの)が選ばれる可能性が高くなる
    少数のモデルであれば、そのようなものが選ばれる可能性は低い(ゼロとは言わないが)
    or 交差検証により、複数のサンプルで学習&検証
    """

対策
    ハイパーパラメータの最適化により、事前にモデルを絞る(1つのPLS + 1つのSVR + ...)
        700サンプルでクロスバリデーション
            ここでも、先ほどのジレンマは当てはまる事に注意
        ホールドアウト 700を500と200に分ける
            さらにオーバーフィットしやすいのであまり使われない

まとめ
    推奨手順 A
        1.1000 → 700 + 300
        2.700サンプルによる交差検証CVで、複数の手法におけるハイパーパラメータを決定
            例：1つのSVR, １つのPLS,...が選ばれる
        3.300サンプルで推定性能を比較し、計算手法を決定
            例：1つのSVRが選ばれる
        4.1000サンプル + 2.で決定したハイパーパラメータ + 3.で決定した手法で学習
        5.1000サンプルにはない、新しいサンプルについて推定。
            この時の推定性能は、3.の結果と同じ、と仮定。
    
    推奨手順 B
        1.ダブルクロスバリデーション = 手順Aの1.の部分にもクロスバリデーションを使う
            クロスバリデーション：ハイパーパラメータ間でのモデルの推定性能の評価
            ダブルクロスバリデーション：複数の手法間でのモデルの推定性能の評価
        以降は同様
    
    注意点
        サンプルを分割する比率(1000 → 700 + 300)にせよ、
        交差検証におけるfold数(上記の比率に関係)にせよ、
        学習用データと、検証用のデータのバランスのジレンマは常にある
一言まとめ
    計算手法による推定性能の比較をしたければダブルクロスバリデーション


[1a3] 構想1
[?] 構造最適化にランダムフォレスト
    原理的に、ランダムフォレストは学習用データのyの範囲を超えることができない
    よってy=エネルギーとするのには向いていない
    一方で、y=力、ストレスとするならば、プラスとマイナスのデータがあれば、ゼロを出力することがある
    また、x=1~5といったように、ある範囲の出力yが一致する
    その範囲を、エネルギーの谷間として考えることができる
ref
20190104 - 構造最適化に混合ガウスモデル
<div>
[?] ベイズ最適化するのに向いてるのは？
    1.探索範囲は狭いが、試行コストが高い
    2.試行コストは安いが、探索範囲が広い
結晶構造の最適化の場合は2.なのでは？
つまり、ランダムサンプリングである程度のデータ数を揃えて置くことは可能
そこから混合ガウスモデル回帰分析をやればいいのでは？
    正規分布の数 = ローカルミニマムの数 とする
    その後、新しいローカルミニマムを発見すれば、そのたびに数を変更する
</div>

[Pythonコードあり] 教師あり混合ガウスモデル(Supervised Gaussian Mixture Models)で
回帰分析も逆解析も自由自在に♪～Gaussian Mixture Regression(GMR)～
https://datachemeng.com/gaussianmixtureregression/

回帰モデル・クラス分類モデルの逆解析～目標のY(物性・活性など)を達成するための
X(説明変数・記述子・特徴量・パラメータ・入力変数)とは？～ 
https://datachemeng.com/inverseanalysis/



[1a4] ベイズ最適化 + SVR + σDD (データ密度によるσ)
[?] ガウス過程回帰以外のベイズ最適化について
    σ = kNNによるデータ密度 (20190101,02)以外にも、
    σ = OCSVMによるデータ密度が可能なのでは？

One-Class Support Vector Machine (OCSVM) で
外れ値・外れサンプルを検出したりデータ密度を推定したりしよう！ 
https://datachemeng.com/ocsvm/

異常検知のための One Class SVM
https://qiita.com/kznx/items/434d98bf1a0e39327542
    2 クラス判別手法である ν-SVM において全訓練パターンがクラス 1 に属し,
        原点を唯一のクラス 2 に属するデータとみなして学習することと同じ
    SVMはパーセプトロンに「カーネル関数」と「マージン最大化」を加えたもの
    もちろんデータセットに応じて最適なカーネル関数は異なると思いますが、
        ガウシアンカーネルを用いればまず間違いありません。

ref
https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
https://scikit-learn.org/stable/auto_examples/svm/plot_oneclass.html
    .predict だと、+1,-1のみだが、
    .decision_function であれば、実数が返ってくる
    このとき、プラスとマイナスの値があるので、
        1.値をプラスのみ
        2.ADから遠いほど、大きい値
    になるように変換する。以下が例
        (a)+側をすべて0にならして、-側を絶対値に変換する
        (b)出力値のmaxで引いて、絶対値を取る 
    ＋規格化で最大値を1にする。
        データが追加されても最大値が変わらないので、変更するべきかもしれない
->
プログラムを組んだ
bayesian_optimizer_SVR_OCSVM.py
    OCSVMのハイパーパラメータ
        kernel=`rbf`で決め打ち
        nu=0.003 (=外れ値の割合。99.7%をAD内部に入れるため)
        gamma:グラム行列を最大化するように設定
    SVRのハイパーパラメータ
        kernel=`rbf`で決め打ち
        gamma:グラム行列を最大化するように設定
        C, epsilon = デフォルト
            要調整？いちいち最適化してると時間がかかって仕方ないが
            もっとも、OCSVMはともかく、ここはSVRでなくてもいい
    x*sin(x) x=[0:10] のopt。iter~10で、x~8へ到達
    kNNに比べてなめらか
    データが固まっている点でもそれなりにσに幅がある

ref
summary/test0_SVM_OCSVM_DCV_rgr.py
